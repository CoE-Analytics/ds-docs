# Model Serving

Databricks Model Serving es un servicio unificado para implementar, gobernar, consultar y monitorear modelos afinados o pre-desplegados por Databricks como Llama 2, MosaicML MPT o BGE, o de cualquier otro proveedor de modelos como Azure OpenAI, AWS Bedrock, AWS SageMaker y Anthropic. Nuestro enfoque unificado facilita experimentar y producir modelos desde cualquier nube o proveedor para encontrar el mejor candidato para su aplicación en tiempo real. Puede realizar pruebas A/B de diferentes modelos y monitorear la calidad del modelo en datos de producción en vivo una vez que se implementen. Model Serving también tiene modelos pre-desplegados como Llama2 70B, lo que le permite impulsar el desarrollo de aplicaciones de IA como RAG (retrieval augmented generation) y proporcionar acceso de pago por token o computación de pago por aprovisionamiento para garantizar el rendimiento.

- Despliegue simplificado para todos los modelos de IA

  Implemente cualquier tipo de modelo, desde modelos de código abierto previamente entrenados hasta modelos personalizados creados a partir de sus propios datos, tanto en CPU como en GPU. La construcción automatizada de contenedores y la gestión de infraestructura reducen los costos de mantenimiento y aceleran la implementación para que pueda concentrarse en desarrollar sus proyectos de IA y ofrecer valor más rápido para su negocio.

- Gestión unificada para todos los modelos

  Administre todos los modelos, incluidos modelos de ML personalizados como PyFunc, scikit-learn y LangChain, modelos fundacionales en Databricks como Llama 2, MPT y BGE, y modelos fundacionales alojados en otros lugares como ChatGPT, Claude 2, Cohere y Stable Diffusion. El servicio de modelos hace que todos los modelos sean accesibles en una interfaz de usuario y una API unificadas, incluidos los modelos hospedados en Databricks o desde otro proveedor de modelos en Azure y AWS.

- Gobernanza incorporada

  Cumple con estrictos requisitos de seguridad y gobernanza, porque puede aplicar los permisos adecuados, monitorear la calidad del modelo, establecer límites de velocidad y realizar un seguimiento del linaje en todos los modelos, ya sea que estén hospedados en Databricks o en cualquier otro proveedor de modelos.

- Modelos centrados en datos

  Acelere las implementaciones y reduzca los errores mediante una integración profunda con Data Intelligence Platform. Puede alojar fácilmente varios modelos de IA generativa, aumentados (RAG) o ajustados con sus datos empresariales. Model Serving ofrece búsquedas, monitoreo y gobernanza automatizados durante todo el ciclo de vida de la IA.

- Rentable

  Sirva modelos como una API de baja latencia en un servicio serverless de alta disponibilidad con soporte para CPU y GPU. Escale sin esfuerzo desde cero para satisfacer sus necesidades más críticas y retroceda a medida que cambien los requisitos. Puede comenzar rápidamente con uno o más modelos preimplementados y cargas de trabajo informáticas de pago por token o de pago por aprovisionamiento para un rendimiento garantizado. Databricks se hará cargo de los costos de mantenimiento y administración de la infraestructura, para que usted pueda concentrarse en brindar valor comercial.
