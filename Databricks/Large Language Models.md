# Large Language Models

Large language models (LLM) son modelos de aprendizaje automático que son muy efectivos para realizar tareas relacionadas con el lenguaje, como traducción, responder preguntas, chat y resumen de contenido, así como generación de contenido y código. Los LLM extraen valor de enormes conjuntos de datos y hacen que ese "aprendizaje" sea accesible desde el primer momento. Databricks simplifica el acceso a estos LLM para integrarlos en sus flujos de trabajo, así como a las capacidades de la plataforma para aumentar, ajustar y pre-entrenar sus LLM utilizando sus propios datos para un mejor rendimiento del dominio.

- Aproveche los LLM para una variedad de casos de uso

  Los LLM pueden impulsar el impacto empresarial en todos los casos de uso e industrias: traducir texto a otros idiomas, mejorar la experiencia del cliente con chatbots y asistentes de inteligencia artificial, organizar y clasificar los comentarios de los clientes, resumir documentos grandes, crear nuevos contenidos de marketing y generar código de software a partir de lenguaje natural. Incluso pueden utilizarse para alimentar otros modelos, como los que generan arte. Algunos LLM populares son la familia de modelos GPT, BERT, Llama, MPT y Anthropic.

- Utilice IA generativa y grandes modelos de lenguaje

  Databricks le permite comenzar con un modelo de lenguaje grande existente como Llama 2, MPT, BGE, OpenAI o Anthropic y aumentarlo o ajustarlo con sus datos empresariales o crear su propio LLM personalizado desde cero mediante pre-entrenamiento. Cualquier LLM existente se puede implementar, gobernar, consultar y monitorear. También hace que sea fácil ampliar estos modelos utilizando técnicas como RAG, el ajuste fino eficiente en parámetros (PEFT) o el ajuste fino estándar.

- Fine-tune de LLMs utilizando sus datos

  Personalice un modelo con sus datos para su tarea específica. Con el soporte de herramientas de código abierto, como Hugging Face y DeepSpeed, puede realizar un LLM básico de manera rápida y eficiente y comenzar a entrenar con sus propios datos para tener más precisión para su dominio y carga de trabajo. Esto también le brinda control para gobernar los datos utilizados para el entrenamiento, de modo que pueda asegurarse de utilizar la IA de manera responsable.

- Pre-entrenamiento de su propio LLM personalizado

  Cree su propio modelo LLM desde cero con pre-entrenamiento de Mosaic AI para garantizar que el conocimiento fundamental del modelo se adapte a su dominio específico. El resultado es un modelo personalizado que se diferencia de forma única y se entrena con los datos únicos de su organización. Mosaic AI Pre-training es una solución de entrenamiento optimizada que puede crear nuevos LLM con miles de millones de parámetros en días con costos de capacitación hasta 10 veces menores.

- LLMOps integrados (MLOps para LLM)

  Utilice MLOps integrados y listos para producción con Managed MLflow para el seguimiento, la gestión y la implementación de modelos. Una vez implementado el modelo, puede monitorear aspectos como la latencia, data drift y más con la capacidad de activar pipelines de reentrenamiento, todo en la misma plataforma unificada de inteligencia de datos para LLMOps de un extremo a otro.

- Datos y modelos en una plataforma unificada

  La mayoría de los modelos se entrenarán más de una vez, por lo que tener los datos de entrenamiento en la misma plataforma de ML será crucial tanto para el rendimiento como para el costo. El entrenamiento de LLMs en Data Intelligence Platform le brinda acceso a herramientas y computación de primer nivel, dentro de un data lake extremadamente rentable, y le permite continuar reentrenando modelos a medida que sus datos evolucionan con el tiempo.
