# Databricks Workflows

Databricks Workflows es un servicio de orquestación administrado, totalmente integrado con Databricks Data Intelligence Platform. Workflows le permiten definir, administrar y monitorear fácilmente flujos de trabajo multitarea para ETL, analytics y pipelines de ML. Con una amplia gama de tipos de tareas admitidas, profundas capacidades de observabilidad y alta confiabilidad, sus equipos de datos están capacitados para automatizar y orquestar mejor cualquier proceso y ser más productivos.

- Unificado con Databricks Data Intelligence Platform

  A diferencia de las herramientas de orquestación externas, Databricks Workflows está completamente integrado con Databricks Data Intelligence Platform. Esto significa que obtiene creación de workflows nativos en su espacio de trabajo y la posibilidad de automatizar cualquier capacidad de la plataforma, incluidos los pipelines de Delta Live Tables, los notebooks y las consultas de Databricks SQL. Con Unity Catalog, obtienes un linaje de datos automatizado para cada workflow, de modo que puedas mantener el control de todos tus activos de datos en toda la organización.

- Fiabilidad a escala

  Todos los días, miles de organizaciones confían en Databricks Workflows para ejecutar millones de cargas de trabajo de producción en AWS, Azure y GCP con un tiempo de actividad del 99,95 %. Tener una herramienta de orquestación totalmente administrada integrada en Data Intelligence Platform significa que no necesita mantener, actualizar ni solucionar problemas de otra herramienta de orquestación independiente.

- Monitoreo profundo y observabilidad

  La integración total con Data Intelligence Platform significa que los Databricks Workflows le brindan una mejor observabilidad que cualquier herramienta de orquestación externa. Mantenga el control obteniendo una vista completa de cada ejecución de flujo de trabajo y configure notificaciones de fallas para alertar a su equipo por correo electrónico, Slack, PagerDuty o un webhook personalizado para que pueda adelantarse a los problemas rápidamente y solucionarlos antes de que los consumidores se vean afectados.

- Batch  y streaming

  Databricks Workflows le proporciona una solución única para organizar tareas en cualquier escenario. Utilice una ejecución de workflow programada para trabajos recurrentes que realizan ingesta por lotes en tiempos preestablecidos o implementan pipelines de datos en tiempo real que se ejecutan continuamente. También puede configurar un workflow para que se ejecute cuando haya nuevos datos disponibles mediante activadores de llegada de archivos.

- Computación eficiente

  La orquestación con Databricks Workflows le ofrece una mejor relación precio/rendimiento para sus cargas de trabajo de producción automatizadas. Obtenga importantes ahorros de costos al utilizar job clusters automatizados que tienen un costo menor y solo se ejecutan cuando un trabajo está programado para que no pague por recursos no utilizados. Además, los shared job clusters le permiten reutilizar recursos informáticos para múltiples tareas para que pueda optimizar la utilización de los recursos.

- Experiencia de usuario perfecta

  Defina flujos de trabajo en su entorno preferido: cree fácilmente flujos de trabajo directamente en la interfaz de usuario del workspace de Databricks o utilizando su IDE favorito. Defina tareas que utilicen un notebook con control de versión en un Databricks Repo o en un repositorio Git remoto y cumpla con las mejores prácticas de DevOps, como CI/CD.
